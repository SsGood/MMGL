{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from emvert_functional_code import emvert_ml\n",
    "from scipy.sparse import csgraph\n",
    "import csv\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "import gc\n",
    "import matplotlib.cm\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy.sparse as spsprs\n",
    "import torch\n",
    "import torch.autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 剔除longitudinal的无用特征列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict_df = pd.read_csv('./6-tadpole_challenge/TADPOLE_D1_D2_Dict.csv')\n",
    "input_df = pd.read_csv('./6-tadpole_challenge/TADPOLE_D1_D2.csv',low_memory=False)\n",
    "PMCI_selection = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove longitudinal feature (12741, 1495)\n",
      "delete columns with all Nan (12741, 1477)\n",
      "only select stable samples from bl to m48 (7405, 1477)\n",
      "data_baseline (1721, 1477)\n",
      "data shape (7405, 1477)\n"
     ]
    }
   ],
   "source": [
    "feature_list = input_df.columns\n",
    "# remove _bl features\n",
    "feature_list = feature_list[~feature_list.str.contains('_bl$')]\n",
    "input_df = input_df[feature_list]\n",
    "\n",
    "#remove longitudinal MRI features\n",
    "feature_list = feature_list[~feature_list.str.upper().str.contains('UCSFFSL')]\n",
    "input_df = input_df[feature_list]\n",
    "print('remove longitudinal feature', input_df.shape)\n",
    "\n",
    "#replace \" \" to nan\n",
    "cond = input_df != \" \"\n",
    "input_df = input_df.where(cond, np.nan)\n",
    "#########cond = input_df != \"-4\"\n",
    "#########input_df = input_df.where(cond, np.nan)\n",
    "\n",
    "#delete columns with all Nan\n",
    "feat_nan = []\n",
    "for feat in feature_list:\n",
    "    if input_df[feat].isnull().all() == True:\n",
    "        feat_nan.append(feat)\n",
    "input_df.drop(feat_nan,axis=1, inplace=True)\n",
    "print('delete columns with all Nan', input_df.shape)\n",
    "\n",
    "#select subjects whose state is NL or MCI or AD. Notice: The selected subjects are state-stable\n",
    "NL_df = input_df[input_df.DXCHANGE == 1]\n",
    "sMCI_df = input_df[input_df.DXCHANGE == 2]\n",
    "AD_df = input_df[input_df.DXCHANGE == 3]\n",
    "pMCI_df = input_df[input_df.DXCHANGE == 5]\n",
    "\n",
    "if PMCI_selection == False:\n",
    "    data = pd.concat([NL_df, sMCI_df, AD_df])\n",
    "else:\n",
    "    data = pd.concat([NL_df, sMCI_df, AD_df, pMCI_df])\n",
    "\n",
    "#select samples from first visit(bl) to 48th month(m48)\n",
    "index = data.VISCODE.str.contains('^bl$|^m06$|^m12$|^m18$|^m24$|^m30$|^m36$|^m42$|^m48$')\n",
    "data = data[index]\n",
    "print('only select stable samples from bl to m48', data.shape)\n",
    "\n",
    "#extract baseline of samples(bl) and the last version of samples\n",
    "data_baseline = data[data.VISCODE == 'bl']\n",
    "#data_last = data.drop_duplicates(subset=['RID'], keep='last')\n",
    "print('data_baseline', data_baseline.shape)\n",
    "assert data_baseline.shape == data_baseline.drop_duplicates(subset=['RID']).shape\n",
    "print('data shape', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>PTID</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>SITE</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>COLPROT</th>\n",
       "      <th>ORIGPROT</th>\n",
       "      <th>EXAMDATE</th>\n",
       "      <th>DXCHANGE</th>\n",
       "      <th>...</th>\n",
       "      <th>PHASE_UPENNBIOMK9_04_19_17</th>\n",
       "      <th>BATCH_UPENNBIOMK9_04_19_17</th>\n",
       "      <th>KIT_UPENNBIOMK9_04_19_17</th>\n",
       "      <th>STDS_UPENNBIOMK9_04_19_17</th>\n",
       "      <th>RUNDATE_UPENNBIOMK9_04_19_17</th>\n",
       "      <th>ABETA_UPENNBIOMK9_04_19_17</th>\n",
       "      <th>TAU_UPENNBIOMK9_04_19_17</th>\n",
       "      <th>PTAU_UPENNBIOMK9_04_19_17</th>\n",
       "      <th>COMMENT_UPENNBIOMK9_04_19_17</th>\n",
       "      <th>update_stamp_UPENNBIOMK9_04_19_17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>bl</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>2005-09-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>011_S_0005</td>\n",
       "      <td>bl</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>2005-09-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>UPENNBIOMK9</td>\n",
       "      <td>P06-MP02-MP01</td>\n",
       "      <td>P06-MP02-MP01/2</td>\n",
       "      <td>2016-11-22</td>\n",
       "      <td>547.3</td>\n",
       "      <td>337</td>\n",
       "      <td>33.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04-20 14:39:54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>011_S_0005</td>\n",
       "      <td>m06</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>2006-03-09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>011_S_0005</td>\n",
       "      <td>m12</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>2006-09-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>UPENNBIOMK9</td>\n",
       "      <td>P06-MP02-MP01</td>\n",
       "      <td>P06-MP02-MP01/2</td>\n",
       "      <td>2016-11-22</td>\n",
       "      <td>472.8</td>\n",
       "      <td>334.1</td>\n",
       "      <td>34.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04-20 14:39:54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>011_S_0005</td>\n",
       "      <td>m24</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>2007-09-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12633</th>\n",
       "      <td>4765</td>\n",
       "      <td>127_S_4765</td>\n",
       "      <td>m48</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ADNI2</td>\n",
       "      <td>ADNI2</td>\n",
       "      <td>2016-06-06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12644</th>\n",
       "      <td>4741</td>\n",
       "      <td>009_S_4741</td>\n",
       "      <td>m48</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ADNI2</td>\n",
       "      <td>ADNI2</td>\n",
       "      <td>2016-08-24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12662</th>\n",
       "      <td>4815</td>\n",
       "      <td>137_S_4815</td>\n",
       "      <td>m48</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ADNI2</td>\n",
       "      <td>ADNI2</td>\n",
       "      <td>2016-09-20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12667</th>\n",
       "      <td>4928</td>\n",
       "      <td>127_S_4928</td>\n",
       "      <td>m48</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ADNI2</td>\n",
       "      <td>ADNI2</td>\n",
       "      <td>2016-09-20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12679</th>\n",
       "      <td>4816</td>\n",
       "      <td>137_S_4816</td>\n",
       "      <td>m48</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ADNI2</td>\n",
       "      <td>ADNI2</td>\n",
       "      <td>2016-09-26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7405 rows × 1477 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RID        PTID VISCODE  SITE  D1  D2 COLPROT ORIGPROT    EXAMDATE  \\\n",
       "0         2  011_S_0002      bl    11   1   1   ADNI1    ADNI1  2005-09-08   \n",
       "10        5  011_S_0005      bl    11   1   0   ADNI1    ADNI1  2005-09-07   \n",
       "11        5  011_S_0005     m06    11   1   0   ADNI1    ADNI1  2006-03-09   \n",
       "12        5  011_S_0005     m12    11   1   0   ADNI1    ADNI1  2006-09-05   \n",
       "13        5  011_S_0005     m24    11   1   0   ADNI1    ADNI1  2007-09-07   \n",
       "...     ...         ...     ...   ...  ..  ..     ...      ...         ...   \n",
       "12633  4765  127_S_4765     m48   127   1   1   ADNI2    ADNI2  2016-06-06   \n",
       "12644  4741  009_S_4741     m48     9   1   1   ADNI2    ADNI2  2016-08-24   \n",
       "12662  4815  137_S_4815     m48   137   1   1   ADNI2    ADNI2  2016-09-20   \n",
       "12667  4928  127_S_4928     m48   127   1   1   ADNI2    ADNI2  2016-09-20   \n",
       "12679  4816  137_S_4816     m48   137   1   1   ADNI2    ADNI2  2016-09-26   \n",
       "\n",
       "       DXCHANGE  ...  PHASE_UPENNBIOMK9_04_19_17 BATCH_UPENNBIOMK9_04_19_17  \\\n",
       "0           1.0  ...                         NaN                        NaN   \n",
       "10          1.0  ...                       ADNI1                UPENNBIOMK9   \n",
       "11          1.0  ...                         NaN                        NaN   \n",
       "12          1.0  ...                       ADNI1                UPENNBIOMK9   \n",
       "13          1.0  ...                         NaN                        NaN   \n",
       "...         ...  ...                         ...                        ...   \n",
       "12633       3.0  ...                         NaN                        NaN   \n",
       "12644       3.0  ...                         NaN                        NaN   \n",
       "12662       3.0  ...                         NaN                        NaN   \n",
       "12667       3.0  ...                         NaN                        NaN   \n",
       "12679       3.0  ...                         NaN                        NaN   \n",
       "\n",
       "       KIT_UPENNBIOMK9_04_19_17 STDS_UPENNBIOMK9_04_19_17  \\\n",
       "0                           NaN                       NaN   \n",
       "10                P06-MP02-MP01           P06-MP02-MP01/2   \n",
       "11                          NaN                       NaN   \n",
       "12                P06-MP02-MP01           P06-MP02-MP01/2   \n",
       "13                          NaN                       NaN   \n",
       "...                         ...                       ...   \n",
       "12633                       NaN                       NaN   \n",
       "12644                       NaN                       NaN   \n",
       "12662                       NaN                       NaN   \n",
       "12667                       NaN                       NaN   \n",
       "12679                       NaN                       NaN   \n",
       "\n",
       "      RUNDATE_UPENNBIOMK9_04_19_17 ABETA_UPENNBIOMK9_04_19_17  \\\n",
       "0                              NaN                        NaN   \n",
       "10                      2016-11-22                      547.3   \n",
       "11                             NaN                        NaN   \n",
       "12                      2016-11-22                      472.8   \n",
       "13                             NaN                        NaN   \n",
       "...                            ...                        ...   \n",
       "12633                          NaN                        NaN   \n",
       "12644                          NaN                        NaN   \n",
       "12662                          NaN                        NaN   \n",
       "12667                          NaN                        NaN   \n",
       "12679                          NaN                        NaN   \n",
       "\n",
       "       TAU_UPENNBIOMK9_04_19_17  PTAU_UPENNBIOMK9_04_19_17  \\\n",
       "0                           NaN                        NaN   \n",
       "10                          337                      33.43   \n",
       "11                          NaN                        NaN   \n",
       "12                        334.1                      34.04   \n",
       "13                          NaN                        NaN   \n",
       "...                         ...                        ...   \n",
       "12633                       NaN                        NaN   \n",
       "12644                       NaN                        NaN   \n",
       "12662                       NaN                        NaN   \n",
       "12667                       NaN                        NaN   \n",
       "12679                       NaN                        NaN   \n",
       "\n",
       "       COMMENT_UPENNBIOMK9_04_19_17  update_stamp_UPENNBIOMK9_04_19_17  \n",
       "0                               NaN                                NaN  \n",
       "10                              NaN              2017-04-20 14:39:54.0  \n",
       "11                              NaN                                NaN  \n",
       "12                              NaN              2017-04-20 14:39:54.0  \n",
       "13                              NaN                                NaN  \n",
       "...                             ...                                ...  \n",
       "12633                           NaN                                NaN  \n",
       "12644                           NaN                                NaN  \n",
       "12662                           NaN                                NaN  \n",
       "12667                           NaN                                NaN  \n",
       "12679                           NaN                                NaN  \n",
       "\n",
       "[7405 rows x 1477 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature selected by RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modal_extraction(feat_dict):\n",
    "    \"\"\"\n",
    "    TODO: \n",
    "    1.Delete invaild information like date and visit code.\n",
    "    2.Separate different modals and corresponding features according to the feature dictionary.\n",
    "    \n",
    "    Parameters:\n",
    "    feat_dict: feature dictionary.\n",
    "    \n",
    "    Return:\n",
    "    modal_feat: modal-specific features dict.\n",
    "    \"\"\"\n",
    "    feat_dict = feat_dict[~feat_dict['FLDNAME'].str.contains('RID|SID|UID|PTID|VISCODE|DATE|FLDSTRENG|FLDSTRENG|VERSION|STATUS|NAME|VISIT')]\n",
    "    feat_modal = feat_dict['TBLNAME']\n",
    "    modal = feat_modal.drop_duplicates(keep = 'last')\n",
    "    modal = modal[modal != \" \"]\n",
    "    modal = list(modal)\n",
    "    detached_feat = []\n",
    "    for i in modal:\n",
    "        temp = list(feat_dict[feat_modal == i]['FLDNAME'])\n",
    "        detached_feat.append(temp)\n",
    "    modal_feat = dict(zip(modal, detached_feat))\n",
    "    return modal_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_feature_processing(data, feat_dict, remove_longitudinal_mri = True, PMCI_selection = False):\n",
    "    # Discrete feature processing\n",
    "    # UCSFFSX = MRI\n",
    "    m_d = modal_extraction(feat_dict)\n",
    "    delete = set(['OVERALLQC_UCSFFSX_11_02_15_UCSFFSX51_08_01_16', \n",
    "                                           'TEMPQC_UCSFFSX_11_02_15_UCSFFSX51_08_01_16', \n",
    "                                           'FRONTQC_UCSFFSX_11_02_15_UCSFFSX51_08_01_16',\n",
    "                                           'PARQC_UCSFFSX_11_02_15_UCSFFSX51_08_01_16',\n",
    "                                           'INSULAQC_UCSFFSX_11_02_15_UCSFFSX51_08_01_16',\n",
    "                                           'OCCQC_UCSFFSX_11_02_15_UCSFFSX51_08_01_16',\n",
    "                                           'BGQC_UCSFFSX_11_02_15_UCSFFSX51_08_01_16',\n",
    "                                           'CWMQC_UCSFFSX_11_02_15_UCSFFSX51_08_01_16',\n",
    "                                           'VENTQC_UCSFFSX_11_02_15_UCSFFSX51_08_01_16'])\n",
    "    m_d['UCSFFSX'] = list(set(m_d['UCSFFSX']) - delete)\n",
    "    '''\n",
    "    data = pd.get_dummies(data, columns = ['OVERALLQC_UCSFFSX_11_02_15_UCSFFSX51_08_01_16', \n",
    "                                           'TEMPQC_UCSFFSX_11_02_15_UCSFFSX51_08_01_16', \n",
    "                                           'FRONTQC_UCSFFSX_11_02_15_UCSFFSX51_08_01_16',\n",
    "                                           'PARQC_UCSFFSX_11_02_15_UCSFFSX51_08_01_16',\n",
    "                                           'INSULAQC_UCSFFSX_11_02_15_UCSFFSX51_08_01_16',\n",
    "                                           'OCCQC_UCSFFSX_11_02_15_UCSFFSX51_08_01_16',\n",
    "                                           'BGQC_UCSFFSX_11_02_15_UCSFFSX51_08_01_16',\n",
    "                                           'CWMQC_UCSFFSX_11_02_15_UCSFFSX51_08_01_16',\n",
    "                                           'VENTQC_UCSFFSX_11_02_15_UCSFFSX51_08_01_16'])\n",
    "    '''\n",
    "    #temp = list(data.columns[data.columns.str.contains('Pass|Fail|Partial|Hippocampus Only')])\n",
    "    #m_d['UCSFFSX'].extend(temp)\n",
    "    #m_d['One_hot'] = temp\n",
    "\n",
    "    # UCBERKELEYAV45 = AV45PET\n",
    "    pass\n",
    "\n",
    "    #DTIROI = DTI\n",
    "    pass\n",
    "\n",
    "    #UPENNBIOMK9 = CSF\n",
    "    m_d['UPENNBIOMK9'] = ['ABETA_UPENNBIOMK9_04_19_17', 'TAU_UPENNBIOMK9_04_19_17', 'PTAU_UPENNBIOMK9_04_19_17']\n",
    "    data.loc[data['ABETA_UPENNBIOMK9_04_19_17'] == '<200', 'ABETA_UPENNBIOMK9_04_19_17'] = 200\n",
    "    data.loc[data['TAU_UPENNBIOMK9_04_19_17'] == '<80', 'TAU_UPENNBIOMK9_04_19_17'] = 80\n",
    "    data.loc[data['TAU_UPENNBIOMK9_04_19_17'] == '>1300', 'TAU_UPENNBIOMK9_04_19_17'] = 1300\n",
    "    data.loc[data['PTAU_UPENNBIOMK9_04_19_17'] == '<8', 'PTAU_UPENNBIOMK9_04_19_17'] = 8\n",
    "    data.loc[data['PTAU_UPENNBIOMK9_04_19_17'] == '>120', 'PTAU_UPENNBIOMK9_04_19_17'] = 120\n",
    "\n",
    "    #Meta_feature\n",
    "    #AGE\n",
    "    min_age, max_age = data.AGE.min(), data.AGE.max()\n",
    "    step, bins, block = 2, [min_age], min_age\n",
    "    while block < max_age:\n",
    "        block += 2\n",
    "        bins.append(block)\n",
    "    data.loc[:,'AGE'] = pd.cut(data.AGE, bins, right = False)\n",
    "    data = pd.get_dummies(data, columns=['AGE'])\n",
    "    #GENDER\n",
    "    data.loc[data.PTGENDER == 'Male', 'PTGENDER'] = 1\n",
    "    data.loc[data.PTGENDER == 'Female', 'PTGENDER'] = 0\n",
    "    #MARRY\n",
    "    data = pd.get_dummies(data, columns = ['PTMARRY'])\n",
    "\n",
    "    #PTEDUCAT\n",
    "    min_educat, max_educat = data.PTEDUCAT.min(), data.PTEDUCAT.max()\n",
    "    step, bins, block = 2, [min_educat], min_educat\n",
    "    while block < max_educat:\n",
    "        block += 2\n",
    "        bins.append(block)\n",
    "    data.loc[:,'PTEDUCAT'] = pd.cut(data.PTEDUCAT, bins, right = False)\n",
    "    data = pd.get_dummies(data, columns=['PTEDUCAT'])\n",
    "    #APOE\n",
    "    data = pd.get_dummies(data, columns=['APOE4'])\n",
    "    \n",
    "    RISK_FACTOR = list(data.columns[data.columns.str.contains('AGE_|PTMARRY|PTEDUCAT|APOE4|PTGENDER')])\n",
    "    # for normal\n",
    "    if PMCI_selection == False:\n",
    "        COGNITIVE_TEST = list(data.columns[data.columns.str.contains('CDRSB|ADAS|MMSE|RAVLT|FAQ|MOCA|Ecog')])\n",
    "        ROI_AVERAGE = list(data.columns[data.columns.str.contains('^FDG$|^AV45$|^Ventricles$|^Hippocampus$|^WholeBrain$|^Entorhinal$|^Fusiform$|^MidTemp$|^ICV$')])\n",
    "        \n",
    "    # for pMCI\n",
    "    else:\n",
    "        COGNITIVE_TEST = list(data.columns[data.columns.str.contains('CDRSB|ADAS|MMSE|RAVLT|FAQ')])\n",
    "        ROI_AVERAGE = list(data.columns[data.columns.str.contains('^Ventricles$|^Hippocampus$|^WholeBrain$|^Entorhinal$|^Fusiform$|^MidTemp$|^ICV$')])\n",
    "    print(ROI_AVERAGE)\n",
    "    m_d['RISK_FACTOR'] = RISK_FACTOR\n",
    "    m_d['COGNITIVE_TEST'] = COGNITIVE_TEST\n",
    "    m_d['ROI_AVERAGE'] = ROI_AVERAGE\n",
    "    m_d.pop('ADNIMERGE')\n",
    "    if remove_longitudinal_mri:\n",
    "        m_d.pop('UCSFFSL')\n",
    "    \n",
    "    data.rename(columns={\"DXCHANGE\": \"LABEL\"}, inplace = True)\n",
    "    return data, m_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_selection(data, based_feat):\n",
    "    \"\"\"\n",
    "    TODO: \n",
    "    1.Select samples whose given features are non-null.\n",
    "    \n",
    "    Parameters:\n",
    "    data       : Data to be processed.\n",
    "    based_feat : given features list.\n",
    "    \n",
    "    Return:\n",
    "    data_non_null: Return the selected samples.\n",
    "    \"\"\"\n",
    "    data_x = data[based_feat]\n",
    "    temp = ~data_x.isnull()\n",
    "    index = temp.all(axis='columns')\n",
    "    data_non_null = data[index]\n",
    "    \n",
    "    return data_non_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "def feature_selection(data_x, feat_dict, modal, num_features_selected):\n",
    "    \"\"\"\n",
    "    TODO: \n",
    "    1.Extract features with given modal from data.\n",
    "    2.Remove the invaild information from the given modal features and remove subjects with Nan given modal feature.\n",
    "    \n",
    "    Parameters:\n",
    "    data_x        : data with all features.\n",
    "    feat_dict     : feature dictionary\n",
    "    modal         : the modal.\n",
    "    \n",
    "    Return:\n",
    "    processed modal features.\n",
    "    \"\"\"\n",
    "    set_modal_feat = set(feat_dict[modal])\n",
    "    #print('The number of specific modal features:', len(set_modal_feat))\n",
    "    set_data_feat = set(data_x.columns)\n",
    "    #print('The number of data features:', len(set_data_feat))\n",
    "    feat_list = list(set_data_feat.intersection(set_modal_feat))\n",
    "    feat_list.append('LABEL')\n",
    "    print('The number of features of intersection between modal and data:', len(feat_list))\n",
    "    \n",
    "    #Obtain feature and label from the given data\n",
    "    data_modal = data_x[feat_list]\n",
    "    data = sample_selection(data_modal, feat_list)\n",
    "    feat = data[data.columns.drop('LABEL')]\n",
    "    label = data['LABEL']\n",
    "    #mask = input_df == \"-4\"\n",
    "    \n",
    "    if len(feat) != 0:\n",
    "    #feature selection by RFE\n",
    "        print('The number of samples applicable to the feature selection condition:', len(feat))\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        input_feat = scaler.fit_transform(feat)\n",
    "        temp = input_feat.copy()\n",
    "        temp = feat.copy()\n",
    "        estimator = RidgeClassifier()\n",
    "        selector = RFE(estimator, num_features_selected, step=200, verbose=1)\n",
    "        selector = selector.fit(temp, label)\n",
    "        selected_feat = list(np.array(feat.columns)[selector.support_])\n",
    "        return selected_feat\n",
    "    else:\n",
    "        print('There is no sample has all the features of Modal '+ modal)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FDG', 'AV45', 'Ventricles', 'Hippocampus', 'WholeBrain', 'Entorhinal', 'Fusiform', 'MidTemp', 'ICV']\n",
      "feature selection for modal: UCSFFSX\n",
      "The number of features of intersection between modal and data: 329\n",
      "The number of samples applicable to the feature selection condition: 2064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/SS_env/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass n_features_to_select=150 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 328 features.\n",
      "--------------------------------------------------------------\n",
      "feature selection for modal: BAIPETNMRC\n",
      "The number of features of intersection between modal and data: 335\n",
      "There is no sample has all the features of Modal BAIPETNMRC\n",
      "--------------------------------------------------------------\n",
      "feature selection for modal: UCBERKELEYAV45\n",
      "The number of features of intersection between modal and data: 234\n",
      "The number of samples applicable to the feature selection condition: 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/SS_env/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass n_features_to_select=150 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 233 features.\n",
      "--------------------------------------------------------------\n",
      "feature selection for modal: UCBERKELEYAV1451\n",
      "The number of features of intersection between modal and data: 239\n",
      "The number of samples applicable to the feature selection condition: 20\n",
      "Fitting estimator with 238 features.\n",
      "--------------------------------------------------------------\n",
      "feature selection for modal: DTIROI\n",
      "The number of features of intersection between modal and data: 229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/SS_env/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass n_features_to_select=150 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples applicable to the feature selection condition: 582\n",
      "Fitting estimator with 228 features.\n",
      "--------------------------------------------------------------\n",
      "feature selection for modal: UPENNBIOMK9\n",
      "The number of features of intersection between modal and data: 4\n",
      "The number of samples applicable to the feature selection condition: 2134\n",
      "--------------------------------------------------------------\n",
      "feature selection for modal: RISK_FACTOR\n",
      "The number of features of intersection between modal and data: 37\n",
      "The number of samples applicable to the feature selection condition: 7405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/SS_env/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass n_features_to_select=150 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n",
      "/usr/local/anaconda3/envs/SS_env/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass n_features_to_select=150 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n",
      "/usr/local/anaconda3/envs/SS_env/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass n_features_to_select=150 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n",
      "/usr/local/anaconda3/envs/SS_env/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass n_features_to_select=150 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n",
      "/usr/local/anaconda3/envs/SS_env/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass n_features_to_select=150 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------\n",
      "feature selection for modal: COGNITIVE_TEST\n",
      "The number of features of intersection between modal and data: 25\n",
      "The number of samples applicable to the feature selection condition: 3144\n",
      "--------------------------------------------------------------\n",
      "feature selection for modal: ROI_AVERAGE\n",
      "The number of features of intersection between modal and data: 10\n",
      "The number of samples applicable to the feature selection condition: 974\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "data_processed, m_d = discrete_feature_processing(data, input_dict_df, PMCI_selection = PMCI_selection)\n",
    "keys = list(m_d.keys())\n",
    "selected_feat = {}\n",
    "for i in keys:\n",
    "    print('feature selection for modal: '+ i)\n",
    "    temp = feature_selection(data_processed, m_d, i, 150)\n",
    "    selected_feat[i] = temp\n",
    "    print('--------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inital_data = data.copy()\n",
    "feat_sam_sel = selected_feat['COGNITIVE_TEST'] + selected_feat['ROI_AVERAGE'] + selected_feat['RISK_FACTOR'] + selected_feat['UPENNBIOMK9']\n",
    "data = sample_selection(data_processed, feat_sam_sel)\n",
    "sample_num, feat_num = data.shape\n",
    "nan_counts = data.apply(lambda x: x.isnull().value_counts())\n",
    "nan_counts[nan_counts.isnull()] = 0\n",
    "temp = nan_counts.iloc[[1]] < int(sample_num * 0.15)\n",
    "avail_feat_set = set(nan_counts.columns[temp.values[0]])\n",
    "for i in selected_feat:\n",
    "    if selected_feat[i] != None:\n",
    "        selected_feat[i] = list(set(selected_feat[i]).intersection(avail_feat_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feat.pop('BAIPETNMRC')\n",
    "selected_feat.pop('UCBERKELEYAV1451')\n",
    "selected_feat.pop('DTIROI')\n",
    "#for pMCI\n",
    "if PMCI_selection == True:\n",
    "    selected_feat.pop('UCBERKELEYAV45')\n",
    "\n",
    "feat_all = []\n",
    "for i in list(selected_feat.values()):\n",
    "    feat_all += i\n",
    "feat_all += ['LABEL']\n",
    "feat_all += ['RID']\n",
    "#feat_all += ['VISCODE']\n",
    "\n",
    "final_data = data[feat_all]\n",
    "#final_data.to_csv(\"processed_data_test.csv\", index = False)\n",
    "#np.save('modal_feat_dict_test.npy',selected_feat)\n",
    "\n",
    "data = final_data\n",
    "data_ = data.drop_duplicates(subset=['RID'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modalities:  dict_keys(['UCSFFSX', 'UCBERKELEYAV45', 'UPENNBIOMK9', 'RISK_FACTOR', 'COGNITIVE_TEST', 'ROI_AVERAGE'])\n",
      "preprocessed data shape:  (598, 366)\n"
     ]
    }
   ],
   "source": [
    "data = data_.drop('RID',axis=1)\n",
    "\n",
    "# Mean Imputation\n",
    "data = data.astype(dtype='float')\n",
    "nan_index = data.isnull().sum()\n",
    "index = nan_index.index\n",
    "for i in index:\n",
    "    if nan_index[i] != 0:\n",
    "        data[i].fillna(data[i].mean(), inplace=True)\n",
    "\n",
    "if PMCI_selection == False:\n",
    "    np.save('./TADPOLE/modal_feat_dict.npy',selected_feat)\n",
    "    data.to_csv(\"./TADPOLE/processed_standard_data.csv\", index = False)\n",
    "else:\n",
    "    data.LABEL[data.LABEL == 5.0] = 4\n",
    "    print('the number of samples with label==4: ', data.LABEL[data.LABEL == 4].shape)\n",
    "    print('the number of samples with label==3: ', data.LABEL[data.LABEL == 3].shape)\n",
    "    print('the number of samples with label==2: ', data.LABEL[data.LABEL == 2].shape)\n",
    "    print('the number of samples with label==1: ', data.LABEL[data.LABEL == 1].shape)\n",
    "    \n",
    "    NL_index = list(np.random.choice(list(data[data.LABEL == 1].index), 211, replace = False))\n",
    "    sMCI_index = list(np.random.choice(list(data.LABEL[data.LABEL == 2].index), 275, replace = False))\n",
    "    AD_index = list(np.random.choice(list(data.LABEL[data.LABEL == 3].index), 72, replace = False))\n",
    "    pMCI_index = list(data[data.LABEL == 4].index)\n",
    "    index = NL_index + sMCI_index + AD_index + pMCI_index\n",
    "    data = data.loc[index]\n",
    "    \n",
    "    np.save('./TADPOLE/modal_feat_dict.npy',selected_feat)\n",
    "    data.to_csv(\"./TADPOLE/processed_standard_data.csv\", index = False)\n",
    "    \n",
    "print('modalities: ', selected_feat.keys())\n",
    "print('preprocessed data shape: ', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
